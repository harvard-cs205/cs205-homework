{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "# For home PC\n",
    "#findspark.init('/home/nick/spark')\n",
    "# For macbook\n",
    "findspark.init('/Users/nick/Documents/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='Shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shakes = sc.textFile('shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_match(line):\n",
    "    \"\"\"Matches all words in a line.\n",
    "    To be used with flatMap, is it returns a tuple of all the words in a given line.\n",
    "    \"\"\"\n",
    "    # Just one or more letters\n",
    "    a_word = re.compile(r\"\\w+\")\n",
    "    # Match all the words in a given line\n",
    "    matches = a_word.findall(line)\n",
    "    \n",
    "    # findall returns a list, so...\n",
    "    return tuple(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = shakes.flatMap(word_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_words(word):\n",
    "    \"\"\"Function that uses regular expressions to filter out words that are made of\n",
    "    entirely capital letters, or entirely capital letters followed by a period, as per\n",
    "    the problem statement.\n",
    "    Note that the way we matched words, \\w+, has already filtered out words made of only numbers.\n",
    "    \"\"\"\n",
    "    \n",
    "    length_of_word = len(word)\n",
    "    \n",
    "    # Matches one or more capital letters in a row.\n",
    "    only_capitals = re.compile(r\"[A-Z]{\" + str(length_of_word) + \"}\")\n",
    "    \n",
    "    # Matches one or more capital letters in a row followed by a period.\n",
    "    only_capitals_period = re.compile(r\"[A-Z]{\" + str(length_of_word-1) + \"}\\.+\")\n",
    "    \n",
    "    # Only numbers\n",
    "    only_numbers = re.compile(r\"\\d{\" + str(length_of_word) + \"}\")\n",
    "    \n",
    "    # if it's a capital...\n",
    "    caps = only_capitals.match(word)\n",
    "    \n",
    "    # if it's a capital followed by a period...\n",
    "    cap_per = only_capitals_period.match(word)\n",
    "    \n",
    "    # if it's a number...\n",
    "    numbs = only_numbers.match(word)\n",
    "        \n",
    "    result = True\n",
    "    if (caps) or (cap_per) or (numbs):\n",
    "        result = False\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = words.filter(filter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'The', 0), (u'Project', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbered_words = words.zipWithIndex()\n",
    "numbered_words.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, u'The'), (0, u'Project'), (1, u'Gutenberg'), (2, u'EBook'), (3, u'of'), (4, u'The'), (5, u'Complete'), (6, u'Works'), (7, u'of'), (8, u'William')]\n",
      "[(0, u'The'), (1, u'Project'), (2, u'Gutenberg'), (3, u'EBook'), (4, u'of'), (5, u'The'), (6, u'Complete'), (7, u'Works'), (8, u'of'), (9, u'William')]\n"
     ]
    }
   ],
   "source": [
    "shifted_words = numbered_words.map(lambda (x, y): (y-1, x))\n",
    "index_words = numbered_words.map(lambda (x, y): (y, x))\n",
    "print shifted_words.take(10)\n",
    "print index_words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = index_words.join(shifted_words)\n",
    "indices_and_pairs = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ((u'The', u'Project'), u'Gutenberg')),\n",
       " (786432, ((u'song', u'of'), u'good'))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_shifted_words = numbered_words.map(lambda (x, y): (y-2, x))\n",
    "almost_there = indices_and_pairs.join(double_shifted_words)\n",
    "almost_there.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'The', u'Project'), u'Gutenberg'),\n",
       " ((u'song', u'of'), u'good'),\n",
       " ((u'shoe', u'trod'), u'upon'),\n",
       " ((u'cue', u'and'), u'my'),\n",
       " ((u'Complete', u'Works'), u'of'),\n",
       " ((u'and', u'his'), u'earth'),\n",
       " ((u'this', u'caparison'), u'and'),\n",
       " ((u'search', u'there'), u'shall'),\n",
       " ((u'William', u'Shakespeare'), u'This'),\n",
       " ((u'la', u'Then'), u'keep')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pairs_and_followed = almost_there.map(lambda (x, y): (y[0], y[1]))\n",
    "all_pairs_and_followed.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine(list_of_word_count_tup1, list_of_word_count_tup2):\n",
    "    \"\"\"Function to combine two \"tuple lists\" of the form [(third_word_1, count_1), ...]\n",
    "    This is to be used with reduceByKey on an RDD of ALL possible occurences of the form (word1, word2), (word3, n).\n",
    "    We want to allow for the case where we encounter new words, and also the case where the lists overlap.\n",
    "    If we have a new word, then we just append it to the list now with count one.\n",
    "    If a word in the second list already exists in the first, we must add their counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First get the list of words that already occur\n",
    "    list_of_words_1 = map(lambda (x, y): x, list_of_word_count_tup1)\n",
    "    \n",
    "    # Now go over every (word, count) pair in the second tuple\n",
    "    for word_count_tup in list_of_word_count_tup2:\n",
    "        \n",
    "        # Access the word for clarity\n",
    "        word = word_count_tup[0]\n",
    "        \n",
    "        # Test membership in the first list\n",
    "        if word in list_of_words_1:\n",
    "            # Find out where it occurred so we can get its count\n",
    "            ind = list_of_words_1.index(word)\n",
    "            # Tuples are immutable, so we recreate the tuple in Python with the updated count\n",
    "            list_of_word_count_tup1[ind] = (word, list_of_word_count_tup1[ind][1]+word_count_tup[1])\n",
    "        else:\n",
    "            # Otherwise, just add away\n",
    "            list_of_word_count_tup1.append(word_count_tup)\n",
    "            \n",
    "    # Return that bad boy\n",
    "    return list_of_word_count_tup1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'The', u'Project'), [(u'Gutenberg', 1)]),\n",
       " ((u'song', u'of'), [(u'good', 1)])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = all_pairs_and_followed.map(lambda (x, y): (x, [(y, 1)]))\n",
    "start.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'thought', u'Suppose'), [(u'that', 1)])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = start.reduceByKey(combine)\n",
    "end.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'apply', u'yourself'), [(u'to', 1)])\n"
     ]
    }
   ],
   "source": [
    "test = end.takeSample(True, 1)\n",
    "test1 = test[0]\n",
    "\n",
    "print test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_phrase(markov, num_words):\n",
    "    \"\"\"Takes a markov chain, assumed to be an RDD of the form described in the problem\n",
    "    and returns a randomly generated phrase with num_words words. The phrase is generated by\n",
    "    choosing a pair of words randomly from the RDD, weighting the next word by the relative\n",
    "    frequencies of occurrences of other words after that pair in Shakespeare, and then\n",
    "    continues to do so until we have num_words.\n",
    "    \"\"\"\n",
    "    # Our counter\n",
    "    curr_num_words = 0\n",
    "    \n",
    "    # Start us off with a blank phrase\n",
    "    phrase = []\n",
    "    \n",
    "    # Keep going until we are done\n",
    "    while (curr_num_words < num_words):\n",
    "        # First flag is for with replacement... doesn't matter because we just do one at a time\n",
    "        # Note that takeSample returns a list, so we just really want one element from it\n",
    "        next_three = markov.takeSample(True, 1)[0]\n",
    "        \n",
    "        # Get the first two words\n",
    "        word_1 = next_three[0][0]\n",
    "        word_2 = next_three[0][1]\n",
    "        \n",
    "        # Now get the list of possible words\n",
    "        poss_words = next_three[1]\n",
    "        \n",
    "        # And choose accordingly...\n",
    "        word_3 = weighted_choice(poss_words)\n",
    "        \n",
    "        # Add our words to the phrase...\n",
    "        phrase.append(word_1)\n",
    "        phrase.append(word_2)\n",
    "        phrase.append(word_3)\n",
    "        \n",
    "        # Make sure we stop at some point\n",
    "        curr_num_words += 3\n",
    "        \n",
    "    # Now we get it to be a string\n",
    "    phrase = ' '.join(phrase)\n",
    "    \n",
    "    # And we are done!\n",
    "    return phrase\n",
    "\n",
    "def weighted_choice(choices):\n",
    "    \"\"\" Inspired by http://stackoverflow.com/questions/3679694/a-weighted-version-of-random-choice\n",
    "    Given a list of tuples, [(x1, c1), (x2, c2), ...]\n",
    "    Returns some xn from the list chosen randomly but weighted by the counts cn.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First get the total count\n",
    "    total = sum(w for c, w in choices)\n",
    "    \n",
    "    # Generate some random number between 0 and the total, uniformly\n",
    "    r = random.uniform(0, total)\n",
    "    \n",
    "    # Variable that stores what \"range\" we are currently in\n",
    "    upto = 0\n",
    "    \n",
    "    # Variable that we will ultimately return\n",
    "    result = choices[-1][0]\n",
    "    \n",
    "    # Loop over all possible choices and weights\n",
    "    for c, w in choices:\n",
    "        \n",
    "        # If our randomly generated number is in the correct range, take it\n",
    "        if upto + w > r:\n",
    "            result = c\n",
    "            \n",
    "        # Otherwise check the next range\n",
    "        upto += w\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "late king s country matters Oph infect to the self confounded to forget am in beguile The tedious gait And speaking\n",
      "force Their scanted hounds are bred lament or fear no my nephew gratulate his safe persuade the King of wheat hid\n",
      "indifferent eye You Blame not this of stay to some glorious day of Darius Transported my tale Right love shall render\n",
      "face That every servant charge thee My master sues loves Caesar best Haven Which is slain as thou possess All the\n",
      "will choose it duty now am grace Well there And fame in and convey what Semiramis this nymph wonders Went you\n",
      "er yet beaten strength even at has forsook him lays she to room comes me shall see If See Buckingham Somerset\n",
      "matters heavy matters Damnable both sides assured Whether yond worms And stop Being a thing daughter Tis he stretch thy chest\n",
      "office And will lord has paid strength my valour stream And in contestation Was theme prince so wild true hearts cannot\n",
      "perpetual honour Dar narrow The throng ll rest us reward thee the Perkes o th at him behind think This amorous\n",
      "This health to letter Edg was loss For Valentine dry again Ros defending it My a homicide One prime And sable\n"
     ]
    }
   ],
   "source": [
    "# Now generate our ten phrases using the Markov Chain\n",
    "for ii in range(10):\n",
    "    print generate_phrase(end, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
