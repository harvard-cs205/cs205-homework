{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"Spark 2\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt \n",
    "# import matplotlib.cm as cm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = sc.textFile('../../DataSources/pg100.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the following type of strings:\n",
    "# -only numbers\n",
    "# -only capitals\n",
    "# -only capitals + period at end\n",
    "def only_num(check_str):\n",
    "    return all([x.isdigit() for x in check_str])\n",
    "def only_caps(check_str):\n",
    "    return all([x.isupper() for x in check_str])\n",
    "def only_caps_period(check_str):\n",
    "    return (any([~x.isdigit() for x in check_str[:-1]]) \n",
    "            and (check_str[-1] == '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_raw = text.flatMap(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simply taking out the non-words will create some artificial sequences. \n",
    "# But maybe this is better than creating holes that will cause dead-ends.\n",
    "text_filtered = words_raw.filter(lambda word: (not only_num(word) \n",
    "                                        and not only_caps(word) \n",
    "                                        and not only_caps_period(word)))\n",
    "\n",
    "# text_filtered = words_raw.map(lambda word: \n",
    "#                               (word if (not only_num(word) \n",
    "#                                         and not only_caps(word) \n",
    "#                                         and not only_caps_period(word)) \n",
    "#                                else u'NaW'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create RDD with triplets of words\n",
    "text_zip = text_filtered.zipWithIndex().map(lambda x: (x[1], x[0]))\n",
    "text_zip1 = text_zip.map(lambda x: (x[0] + 1, x[1]))\n",
    "text_zip2 = text_zip.map(lambda x: (x[0] + 2, [x[1]]))\n",
    "text_triplet_filt = (text_zip.join(text_zip1)\n",
    "                .join(text_zip2)\n",
    "                .map(lambda x: x[1])\n",
    "                .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def rmv_missing(x):\n",
    "#     return ((x[0][0] != u'NaW') \n",
    "#             and (x[0][1] != u'NaW') \n",
    "#             and (x[1][0] != u'NaW'))\n",
    "# text_triplet_filt = text_triplet.filter(rmv_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce by key\n",
    "text_triplet_redu = text_triplet_filt.reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gather all the counts of each possibility\n",
    "def val_counts(redund_list):\n",
    "    words, counts = np.unique(redund_list, return_counts=True)\n",
    "    return [(words[word_i], counts[word_i]) for word_i in range(len(words))]\n",
    "\n",
    "text_counts = text_triplet_redu.map(lambda x: (x[0], val_counts(x[1])))\n",
    "\n",
    "# Strange hack recommended by pset\n",
    "text_counts = text_counts.map(lambda x: x).cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Done with the markov model, now generate random sequences ###\n",
    "# Take random sample from RDD\n",
    "n_phrases = 10\n",
    "init_pair_list = [elem[0] for elem in text_counts.takeSample(False, n_phrases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_next_word(curr_choices):\n",
    "    choice_len = len(curr_choices)\n",
    "    probs = [1.0 * x[1] / choice_len for x in curr_choices]\n",
    "    return curr_choices[np.random.choice(choice_len, 1, probs)[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase_len = 20\n",
    "all_phrases = []\n",
    "for phrase_i in range(n_phrases):\n",
    "    init_words = init_pair_list[phrase_i]\n",
    "    curr_words = []\n",
    "    curr_words.append(init_words[0])\n",
    "    curr_words.append(init_words[1])\n",
    "\n",
    "    for word_i in range(phrase_len - 2):\n",
    "        new_key = (curr_words[-2], curr_words[-1])\n",
    "\n",
    "        # look up element in RDD\n",
    "        curr_choices = text_counts.lookup(new_key)[0]\n",
    "\n",
    "        # pick next word\n",
    "        new_word = pick_next_word(curr_choices)\n",
    "\n",
    "        # append it to curr_words\n",
    "        curr_words.append(new_word)\n",
    "    all_phrases.append(curr_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save list of strings to file\n",
    "def save_str_list(test_strs):\n",
    "    with open('P6.txt', 'a') as f:\n",
    "        for word_i, word in enumerate(test_strs):\n",
    "            f.write(word)\n",
    "            if word_i < len(test_strs) - 1:\n",
    "                f.write(' ')\n",
    "            else:\n",
    "                f.write('.\\n\\n')\n",
    "                \n",
    "for phrase in all_phrases:\n",
    "    save_str_list(phrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
