{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/shenjeffrey/spark/')\n",
    "import pyspark\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate spark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1609',\n",
       " u'',\n",
       " u'THE SONNETS',\n",
       " u'',\n",
       " u'by William Shakespeare',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'                     1',\n",
       " u'  From fairest creatures we desire increase,']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "data = sc.textFile(\"shakespeare.txt\")\n",
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1609',\n",
       " u'',\n",
       " u'THE',\n",
       " u'SONNETS',\n",
       " u'',\n",
       " u'by',\n",
       " u'William',\n",
       " u'Shakespeare',\n",
       " u'',\n",
       " u'']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = 'ADH.'\n",
    "test2 = '234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADH.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.upper() == test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterNonWords(word):\n",
    "    # take out empty strings\n",
    "    if word == '':\n",
    "        return False\n",
    "    # take out words w/ only numbers\n",
    "    elif word.isdigit():\n",
    "        return False\n",
    "    # take out words with all Capital characters\n",
    "    # will also take out words with Capital characters w/ a period at the end\n",
    "    elif word == word.upper():\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = data.filter(filterNonWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "818620"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'by',\n",
       " u'William',\n",
       " u'Shakespeare',\n",
       " u'From',\n",
       " u'fairest',\n",
       " u'creatures',\n",
       " u'we',\n",
       " u'desire',\n",
       " u'increase,',\n",
       " u'That',\n",
       " u'thereby',\n",
       " u\"beauty's\",\n",
       " u'rose',\n",
       " u'might',\n",
       " u'never',\n",
       " u'die,',\n",
       " u'But',\n",
       " u'as',\n",
       " u'the',\n",
       " u'riper']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data2 = clean_data.collect()[1:] + [\"\"]\n",
    "clean_data3 = clean_data2[1:] + [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put them back into RDD\n",
    "clean_data2 = sc.parallelize(clean_data2)\n",
    "clean_data3 = sc.parallelize(clean_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'by', u'William', u'Shakespeare', u'From', u'fairest', u'creatures', u'we', u'desire', u'increase,', u'That']\n",
      "[u'William', u'Shakespeare', u'From', u'fairest', u'creatures', u'we', u'desire', u'increase,', u'That', u'thereby']\n",
      "[u'Shakespeare', u'From', u'fairest', u'creatures', u'we', u'desire', u'increase,', u'That', u'thereby', u\"beauty's\"]\n"
     ]
    }
   ],
   "source": [
    "print clean_data.take(10)\n",
    "print clean_data2.take(10)\n",
    "print clean_data3.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.zipWithIndex().map(lambda (x,y): (y,x))\n",
    "clean_data2 = clean_data2.zipWithIndex().map(lambda (x,y): (y,x))\n",
    "clean_data3 = clean_data3.zipWithIndex().map(lambda (x,y): (y,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'by'), (1, u'William'), (2, u'Shakespeare'), (3, u'From'), (4, u'fairest'), (5, u'creatures'), (6, u'we'), (7, u'desire'), (8, u'increase,'), (9, u'That')]\n",
      "[(0, u'William'), (1, u'Shakespeare'), (2, u'From'), (3, u'fairest'), (4, u'creatures'), (5, u'we'), (6, u'desire'), (7, u'increase,'), (8, u'That'), (9, u'thereby')]\n",
      "[(0, u'Shakespeare'), (1, u'From'), (2, u'fairest'), (3, u'creatures'), (4, u'we'), (5, u'desire'), (6, u'increase,'), (7, u'That'), (8, u'thereby'), (9, u\"beauty's\")]\n"
     ]
    }
   ],
   "source": [
    "print clean_data.take(10)\n",
    "print clean_data2.take(10)\n",
    "print clean_data3.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ((u'by', u'William'), u'Shakespeare')),\n",
       " (655360, ((u'dagger.]', u'This'), u'is')),\n",
       " (524290, ((u'most', u'of'), u'me!')),\n",
       " (393220, ((u'in', u'a'), u'country')),\n",
       " (262150, ((u'here', u'in'), u'arms')),\n",
       " (786440, ((u'sweet', u'consort;'), u'to')),\n",
       " (655370, ((u'die.', u'She'), u'stabs')),\n",
       " (524300, ((u'and', u'might'), u'To')),\n",
       " (393230, ((u'and', u'Burgundy;'), u'Attendants.')),\n",
       " (262160, ((u\"King's,\", u'we'), u'charge'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram = clean_data.join(clean_data2).join(clean_data3)\n",
    "n_gram.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'by', u'William', u'Shakespeare'), 1),\n",
       " ((u'dagger.]', u'This', u'is'), 1),\n",
       " ((u'most', u'of', u'me!'), 1),\n",
       " ((u'in', u'a', u'country'), 1),\n",
       " ((u'here', u'in', u'arms'), 1),\n",
       " ((u'sweet', u'consort;', u'to'), 1),\n",
       " ((u'die.', u'She', u'stabs'), 1),\n",
       " ((u'and', u'might', u'To'), 1),\n",
       " ((u'and', u'Burgundy;', u'Attendants.'), 1),\n",
       " ((u\"King's,\", u'we', u'charge'), 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram = n_gram.map(lambda (key, val): ((val[0][0], val[0][1],val[1]), (1)))\n",
    "n_gram.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'we', u'do', u'establish'), 1),\n",
       " ((u'world.', u'You', u'are'), 1),\n",
       " ((u'not', u'permanent-', u'sweet,'), 1),\n",
       " ((u'a', u'friend', u'of'), 8),\n",
       " ((u'whale', u'on', u'ground,'), 1),\n",
       " ((u'us', u'consult', u'upon'), 1),\n",
       " ((u'The', u'breath', u'no'), 1),\n",
       " ((u'speak', u'What', u'have'), 1),\n",
       " ((u'radiant', u'Queen', u'hates'), 1),\n",
       " ((u'he,', u'nor', u'his'), 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram = n_gram.reduceByKey(lambda x,y: x+y)\n",
    "n_gram.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'we', u'do'), (u'establish', 1)),\n",
       " ((u'world.', u'You'), (u'are', 1)),\n",
       " ((u'not', u'permanent-'), (u'sweet,', 1)),\n",
       " ((u'a', u'friend'), (u'of', 8)),\n",
       " ((u'whale', u'on'), (u'ground,', 1)),\n",
       " ((u'us', u'consult'), (u'upon', 1)),\n",
       " ((u'The', u'breath'), (u'no', 1)),\n",
       " ((u'speak', u'What'), (u'have', 1)),\n",
       " ((u'radiant', u'Queen'), (u'hates', 1)),\n",
       " ((u'he,', u'nor'), (u'his', 1))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram = n_gram.map(lambda (key, val): ((key[0],key[1]),(key[2], val)))\n",
    "n_gram.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'shadows;', u'and'), [(u'the', 1)]),\n",
       " ((u'meantime,', u'lady,'), [(u\"I'll\", 1)]),\n",
       " ((u'Where', u'intend'), [(u'holy', 1)]),\n",
       " ((u'Exit', u'Hast'), [(u'thou', 1)]),\n",
       " ((u'fools', u'have'), [(u'brought', 1), (u'was', 1)]),\n",
       " ((u'blastments', u'are'), [(u'most', 1)]),\n",
       " ((u'stretching', u'thee,'), [(u'And', 1)]),\n",
       " ((u\"'twere\", u'far'), [(u'off;', 1)]),\n",
       " ((u'sight', u'For'), [(u'terror,', 1), (u'fear', 1)]),\n",
       " ((u'Play,', u'music,'), [(u'then.', 1)])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram = n_gram.groupByKey().mapValues(list)\n",
    "n_gram.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = n_gram.collectAsMap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'the', 9),\n",
       " (u'he', 1),\n",
       " (u'it', 3),\n",
       " (u'this', 1),\n",
       " (u'be', 1),\n",
       " (u'his', 1),\n",
       " (u'your', 1),\n",
       " (u'a', 1),\n",
       " (u'that', 1),\n",
       " (u'my', 2),\n",
       " (u'Mortimer', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Now', 'is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_weights(third_word_list):\n",
    "    weights = []\n",
    "    for word in third_word_list:\n",
    "#         print word\n",
    "        weights += [word[0]] * word[1]\n",
    "    return weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sentence(n_gram, sentence_length=20):\n",
    "    # Declare blank sentence\n",
    "    sentence = []\n",
    "    # Take a random sample from the RDD\n",
    "#     random_sample = n_gram.takeSample(True, 1,12)\n",
    "    random_sample = n_gram.takeSample(True, 1)\n",
    "    # First word\n",
    "    first_word = random_sample[0][0][0]\n",
    "    second_word = random_sample[0][0][1]\n",
    "    third_word_list = random_sample[0][1]\n",
    "    look_up_key = (first_word, second_word)\n",
    "#     print \"first word: \",first_word\n",
    "#     print \"second word: \",second_word\n",
    "#     print \"third word list: \",third_word_list\n",
    "#     print \"starting lookup: \",look_up_key\n",
    "    sentence += [first_word] + [second_word]\n",
    "#     print \"start sentence: \",sentence\n",
    "    # loop until sentence length is greater than 20\n",
    "    while len(sentence) < sentence_length:\n",
    "        # create weights\n",
    "        weights = generate_weights(third_word_list)\n",
    "#         print \"weights: \", weights\n",
    "        # use np.random.choice\n",
    "        third_word = np.random.choice(weights)\n",
    "#         print \"third word: \", third_word\n",
    "        \n",
    "        # update sentence and look up key\n",
    "        sentence += [third_word]\n",
    "        look_up_key = (look_up_key[1], third_word)\n",
    "#         print \"look_up_key: \", look_up_key\n",
    "        third_word_list = n_gram.map(lambda x: x).lookup(look_up_key)\n",
    "#         print \"new third word list: \", third_word_list\n",
    "        third_word_list = third_word_list[0]\n",
    "        \n",
    "    print ' '.join(sentence)\n",
    "    return ' '.join(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and, not consulting, broke Into a thousand grains That issue out of hearing To th' vulgar eye, that false peer,\n",
      "chokes The hollow passage of their particular functions and wonder if Titania be awak'd; Then, what it is. Come, go\n",
      "Than all the hot-bloods between fourteen and fourteen and a little before. [Exeunt all but would fain have drink. This\n",
      "Bohemia can learnedly handle, though they are no venereal signs. Vengeance is in GIoucestershire- 'Twas where you are, Make them\n",
      "Count Did see her, hear her, at that instant Crav'd audience; and wherein It shall be while you are waspish.\n",
      "Princes. Exit London. street Enter and at a strife? What is the day appointed for the witch of Brainford. But\n",
      "Montano, you were wont. There's a good husband. Pedro. And when have requir'd Some heavenly power guide us Out of\n",
      "have outfac'd them all. Let it stamp wrinkles in my life, by some other messenger. Back, slave, or thou look'st\n",
      "For Doll is in. Pistol speaks nought but fame; And every tongue that speaks thus their voice? I'll give you\n",
      "weakness, married to her eyes, Till she herself revil'd you there. Exit [Reads] have sent to her country. Hear me,\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(10):\n",
    "    generate_sentence(n_gram, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
