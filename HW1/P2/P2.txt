I used a uniform random distribution to partition the data into 100 partitions. Looking at the histogram, it is clear that the random partition had a much more uniform load. It isn't exactly the same but it is a normal distributition with a small variance. On the other hand, using the defualt partition meant that most partitions did little work, but some did a lot of work. Although what's intersting is that there was no shuffle read/write for the default partition and the random partition had about 320kb of shuffle per partition. This could be due to the fact taht the default keeps items with similar data in the same partition reducing shuffle. 