# Your discussion here
My strategy to balance work load came from a consideration of the picture of the mandelbrot fractal. A lot of work seems to be done in the middle and on the axis of the fractal. Doing a simple cartesian product and naively partitioning is not a good design. Because it will sort of mesh the domain and some cell will have a lot more work which is very unbalanced as you can see in P2a_hist.

My strategy was to rearange the bashes to balance the load using the modulo function. The implementation is that I gave a key to each batch which was the index of the pixel modulo 100 (because we have 100 partition). I am the slicing the domain and each batch has a 1-pixel large slice every 100 slice, so they allsome work from the work-intensive area. We see in P2b_hist.png that it is a winning strategy since now the work is balanced. Every worker does about 2 millions instructions.

We just answered (a) in the previous paragraph. Let's now talk about (b) the cost of this balancing. The balancing cost a mapping (to get the keys that will permit to rearange the work point distribution per worker in the partition) and a shuffle in the partitionBy(100). For the balancing to be time efficient, you need those 2 operations to take less time that 9 times the computing cost of 2 million instruction (since in the naive approach, the stragglers have to compute up to 20 million instructions).
