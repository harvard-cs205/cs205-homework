In the file 'original_partitioning.pdf' I have mapped out the values for the first 3 partitions, where the axes are index. As you can, see each partition is assigned to a small box sequentially by index. Because all of the points in, for example, the bottom left corner of the plot require very few iterations, the first partition will finish very rapidly. The partitions that contain only points in the middle of the graph will take much longer to finish. The histogram 'No_Fancy_partitioning.pdf' shows that many of the partitions took few iterations to complete, but there were a few that took ~10^7 counts to finish, orders of magnitude higher.

I chose to repartition the RDD in a bit of a silly/dangerous way, but one that required no shuffle. Rather than forming the RDD and then shuffling, I simply reshaped the index array before parallelizing it. This might not scale well, but for this problem it worked really well. I also relied somewhat on knowing the partitioning before doing the reshaping. I have plotted the first three partitions again in the file 'new_partitioning.pdf.' As you can see, each partition samples each part of the map. The histogram 'Evenly_sampled_partitioning.pdf' shows that the work done by all of the partitions is the same to within a factor of 2. 