{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shortest_path(sc, adj_matrix_rdd, start_name, end_name, diameter=float(\"inf\")):\n",
    "    '''\n",
    "    Takes SparkContext (sc), adjacency matrix rdd (adj_matrix_rdd), character name (char), and optional diameter\n",
    "    of graph as parameter and performs BFS.\n",
    "    Note: adj_matrix_rdd contains \n",
    "        key = character name\n",
    "        value = list of names of adjacent characters\n",
    "    Note: adj_matrix_rdd should be hash partitioned into 100 parts\n",
    "    Returns (path length, list of nodes in path (including start))\n",
    "    '''\n",
    "\n",
    "    def make_neighbor_key(neighbors,prev_dist, path_to_current):\n",
    "        #helper function for transforming values in RDDs\n",
    "        return [(n, (prev_dist +1, path_to_current+[n])) for n in neighbors]\n",
    "    \n",
    "    dist = 0\n",
    "    #paths_rdd with hold:\n",
    "    #    key = name at end of path\n",
    "    #    value = (path length, path) where path = list of nodes in path in order \n",
    "    #                               (i.e. [1st node name in path after start, second node name in path, ..., last node name in path])\n",
    "    paths_rdd = sc.parallelize([(start_name,(dist, [start_name]))]).partitionBy(100) \n",
    "    neighbors_rdd = paths_rdd\n",
    "    num_touched = 1\n",
    "    #We assume graph diameter is <=10\n",
    "    i = 0\n",
    "    num_new_neighbors = 1 \n",
    "    while (i < diameter) and (num_new_neighbors != 0):\n",
    "        dist += 1\n",
    "        #get neighbors of neighbors\n",
    "        neighbors_rdd = neighbors_rdd.join(adj_matrix_rdd) \n",
    "        \n",
    "        #we have (current node, (prev_dist, path_to_current_node, [neighbor1, neighbor2, ...])\n",
    "        # we want (neighbor 1, (path_length, path_to neighbor1))\n",
    "        #         ...\n",
    "        # -->new_neighbors_rdd\n",
    "        #eliminate duplicates, we only need one path to a node\n",
    "        #print neighbors_rdd.values().take(1)\n",
    "        neighbors_rdd = neighbors_rdd.values()\\\n",
    "            .flatMap(lambda ((prev_dist, path_to_current), neighbors): make_neighbor_key(neighbors,prev_dist,path_to_current))\\\n",
    "            .reduceByKey(lambda _, val: val)\\\n",
    "            .partitionBy(100)\n",
    "        #we now have rdd of (char,dist)\n",
    "        assert neighbors_rdd.partitioner == paths_rdd.partitioner, \"neighbors and dists are not copartitioned\"\n",
    "        #get only unexplored nodes / remove nodes that we already have a shorter path to\n",
    "        neighbors_rdd = neighbors_rdd.subtractByKey(paths_rdd)\n",
    "        neighbors_rdd.cache()\n",
    "        num_new_neighbors = neighbors_rdd.count()\n",
    "        num_touched += num_new_neighbors\n",
    "        #update dists_rdd to include the new nodes we have explored\n",
    "        paths_rdd = paths_rdd.union(neighbors_rdd)\n",
    "        i += 1\n",
    "        path_to_end = paths_rdd.lookup(end_name)\n",
    "        if path_to_end != []:\n",
    "            return path_to_end[0]\n",
    "    print num_touched\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
