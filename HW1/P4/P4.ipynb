{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"Spark1\")\n",
    "import re\n",
    "#from P4_bfs import bfs\n",
    "def bfs(sc, adj_matrix_rdd, char, diameter=float(\"inf\")):\n",
    "    '''\n",
    "    Takes SparkContext (sc), adjacency matrix rdd (adj_matrix_rdd), character name (char), and optional diameter\n",
    "    of graph as parameter and performs BFS.\n",
    "    Note: adj_matrix_rdd contain \n",
    "        key = character name\n",
    "        value = list of names of adjacent characters                   \n",
    "    '''\n",
    "    def group_neighbor_dist(neighbors,dist):\n",
    "        return [(n,dist) for n in neighbors]\n",
    "    \n",
    "    dist = 0\n",
    "    dists_rdd = sc.parallelize([(char,dist)]).partitionBy(32) #shortest paths to nodes\n",
    "    neighbors_rdd = dists_rdd\n",
    "    num_touched = 1\n",
    "    #We assume graph diameter is <=10\n",
    "    i = 0\n",
    "    num_new_neighbors = 1 \n",
    "    while (i < diameter) and (num_new_neighbors != 0):\n",
    "        #get neighbors of neighbors\n",
    "        neighbors_rdd = neighbors_rdd.join(adj_matrix_rdd) \n",
    "        #we only care about the new neighbors\n",
    "        neighbors_rdd = neighbors_rdd.values()\\\n",
    "            .flatMap(lambda (prev_dist,neighbors): group_neighbor_dist(neighbors,prev_dist+1))\\\n",
    "            .distinct()\\\n",
    "            .partitionBy(32)\n",
    "            \n",
    "        #we now have rdd of (char,dist)\n",
    "        assert neighbors_rdd.partitioner == dists_rdd.partitioner, \"neighbors and dists are not copartitioned\"\n",
    "        #remove characters that we already have a shorter path to\n",
    "        neighbors_rdd = neighbors_rdd.subtractByKey(dists_rdd) \n",
    "        neighbors_rdd.cache()\n",
    "        num_new_neighbors = neighbors_rdd.count()\n",
    "        num_touched += num_new_neighbors\n",
    "        #update dists_rdd to include the new nodes we have explored\n",
    "        dists_rdd = dists_rdd.union(neighbors_rdd)\n",
    "        i += 1\n",
    "        \n",
    "    print num_touched\n",
    "    return dists_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#source_rdd will contain (key=character, value=a comic that the character is in)\n",
    "source_rdd = sc.textFile(\"source.csv\",100)\n",
    "cleaner_regex = re.compile('\"(.+)\",\"(.+)\"')\n",
    "source_rdd = source_rdd.map(lambda line: cleaner_regex.search(line).groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#comic_rdd will contain (key=comic, value=list of characters in the comic)\n",
    "comic_rdd = source_rdd.map(lambda (character, comic): (comic, [character]))\n",
    "comic_rdd = comic_rdd.reduceByKey(lambda chars1, chars2: chars1 + chars2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#char_rdd will contain (key=character, value=set of comics the character is in)\n",
    "char_rdd = source_rdd.map(lambda (character, comic): (character, set([comic])))\n",
    "char_rdd = char_rdd.reduceByKey(lambda chars1, chars2: chars1.union(chars2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[14] at mapPartitions at PythonRDD.scala:342"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we want to make adj_matrix_rdd which contains \n",
    "#(key=character1, value=set of characters that appear in some comic with character1)\n",
    "\n",
    "#dictionary where key=comic, value=list of characters in the comic\n",
    "comic_dict = comic_rdd.collectAsMap()\n",
    "\n",
    "def flatten (lst_of_lsts):\n",
    "    #helper function that takes a list of list and returns a flattened list\n",
    "    flat = []\n",
    "    for l in lst_of_lsts:\n",
    "        flat.extend(l)\n",
    "    return flat\n",
    "\n",
    "adj_matrix_rdd = char_rdd.map(lambda (char,comics): (char, list(set(flatten([comic_dict[comic] for comic in comics])))))\n",
    "adj_matrix_rdd = adj_matrix_rdd.partitionBy(100)\n",
    "adj_matrix_rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#BFS using RDDs\n",
    "sources = ['CAPTAIN AMERICA','MISS THING/MARY','ORWELL']\n",
    "#call into bfs\n",
    "for source in sources:\n",
    "    bfs(sc, adj_matrix_rdd, source, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
