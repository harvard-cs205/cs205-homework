{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.ticker as ticker   \n",
    "\n",
    "from P4_bfs import *\n",
    "\n",
    "# setup spark\n",
    "conf = SparkConf().setAppName('Graph Processing')\n",
    "sc = SparkContext(conf=conf)\n",
    "from P4_bfs import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conversion from MarvelGraph to adj. list representation\n",
    "comicRDD = sc.textFile('source.csv').map(lambda x: x.split('\",\"')).map(lambda x: (x[0][1:], x[1][:len(x[1])-1]))\n",
    "\n",
    "# create Dict (last part can be removed as it does only make indices 1-based)\n",
    "dictRDD = comicRDD.map(lambda x: x[0]).distinct().sortBy(lambda x: x).zipWithIndex().map(lambda x: (x[0], x[1]+1))\n",
    "\n",
    "# convert Character to integer for later join!\n",
    "comicRDD = comicRDD.join(dictRDD).map(lambda x: (x[1][0], x[1][1])).cache()\n",
    "\n",
    "# join on Comic Issue & remove all reflexive edges\n",
    "graphRDD = comicRDD.join(comicRDD).map(lambda x: (x[1][0], x[1][1])).filter(lambda x: x[0] != x[1])\n",
    "\n",
    "# now group s.t. we have for each vertex an adjacency list of nodes\n",
    "graphRDD = graphRDD.groupByKey().map(lambda x: (x[0], list(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISS THING/MARY : 6407 nodes visited\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "#v0 = [characterDict['CAPTAIN AMERICA'], characterDict['MISS THING/MARY'], characterDict['ORWELL']]\n",
    "v0 = [characterDict['MISS THING/MARY']]\n",
    "\n",
    "for i in range(0, len(v0)):\n",
    "    num_visited_nodes, rdd = sparkBFS(sc, graphRDD, v0[i])\n",
    "    \n",
    "    print('%s : %d nodes visited' % (vertexDict[str(v0[i])], num_visited_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'MISS THING/MARY'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup code\n",
    "def lookUpVertexID(dictRDD, character):\n",
    "    return dictRDD.filter(lambda x: x[0] == character).collect()[0][1]\n",
    "\n",
    "def lookUpCharacter(dictRDD, vertexID):\n",
    "    return dictRDD.filter(lambda x: x[1] == vertexID).collect()[0][0]\n",
    "\n",
    "lookUpCharacter(dictRDD, lookUpVertexID(dictRDD, 'MISS THING/MARY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comicdf = pd.read_csv('source.csv', names=['Character', 'ComicIssue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = comicdf['Character'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = range(1, len(keys)+1) # start indices with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "characterDict = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characterDict['FROST, CARMILLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create graph by adjacency list (there is a connection between\n",
    "# two characters if they appear in the same comic issue)\n",
    "\n",
    "# therefore join the comicdf on comic issue!\n",
    "mergeddf = pd.merge(comicdf, comicdf, how='inner', on='ComicIssue')\n",
    "\n",
    "# now remove ComicIssue & all rows with Character_x == Character_y\n",
    "filtereddf = mergeddf.drop('ComicIssue', 1)\n",
    "filtereddf = filtereddf[filtereddf['Character_x'] != filtereddf['Character_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform string to integers for performance reasons\n",
    "edgedf = filtereddf.applymap(lambda x: characterDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# save the edge list and the dictionary as two separate csv's\n",
    "edgedf.to_csv('edge_list.csv', header=False, index=False)\n",
    "\n",
    "writer = csv.writer(open('characters.csv', 'wb'))\n",
    "entries = sorted(characterDict.items(), key=lambda x: x[1]);\n",
    "for key, value in entries:\n",
    "    writer.writerow([value, key]) # flip it (so the vertex index is now the key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load vertex dictionary (is basically the character dictionary inverted)\n",
    "reader = csv.reader(open('characters.csv', 'rb'))\n",
    "vertexDict = dict(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function prepares the rdd\n",
    "def prepare_rdd(filename):\n",
    "    rdd = sc.textFile(filename)\n",
    "\n",
    "    # map string to tuples\n",
    "    rdd = rdd.map(lambda x: x.split(','))\n",
    "    rdd = rdd.map(lambda x: (int(x[0]), int(x[1])))\n",
    "    \n",
    "    # now group s.t. we have for each vertex an adjacency list of nodes\n",
    "    rdd = rdd.groupByKey().map(lambda x: (x[0], list(x[1])))\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test code\n",
    "filename = 'edge_list.csv'#'edge_list_simple.csv' # 'edge_list.csv'\n",
    "\n",
    "rdd = prepare_rdd(filename)\n",
    "#rdd.take(5)\n",
    "v0 = [characterDict['CAPTAIN AMERICA'], characterDict['MISS THING/MARY'], characterDict['ORWELL']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTAIN AMERICA : 6407 nodes visited\n",
      "MISS THING/MARY : 6 nodes visited\n",
      "ORWELL : 8 nodes visited\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(v0)):\n",
    "    rdd = prepare_rdd(filename)\n",
    "    num_visited_nodes, rdd = sparkBFS(sc, rdd, v0[i])\n",
    "    \n",
    "    print('%s : %d nodes visited' % (vertexDict[str(v0[i])], num_visited_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CAPTAIN AMERICA'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertexDict[str(v0[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_visited_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
