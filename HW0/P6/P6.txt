# Your answers here
#
6a) The 'unexpected' results are that the jobs do not necessary finish in the original order. For example. at times we find that job 3 will finish, and thus job 5 will start, before job 2 terminates. This makes sense because the different processes are potentially being batched off to different CPUs, and there are no guarantees by the system about which order they will terminate (there is no waiting for the other ones). This could affect how we program because we have to make sure that we are not depending on the sort of sequential output that this would guarantee. For example, if we wanted to print every number from 1 to 1000000 in order, this would probably not be a good approach. On the other hand, if we can redesign the code so that that is not necessary, such as if we are doing weather modeling of the globe and each sector of the globe can be computed independently of all others, then this sort of parellel process can allow for very fast computation.

6b) In general, it is appears that as the wait time increases, the ratio gets higher. In other words, as the wait time increases, the serial approach gets worse by more than the parallel approach. In fact, as you can see towards the bottom left of the image, it is possible for the serial time to be faster. Basically, it is faster when the actual 'computation' that is occuring on each call is quite fast (lower wait time). This makes sense, because if the computations are quite fast, then it may not be worth the overhead to create several processes, distribute them, collect results, etc. 

 
