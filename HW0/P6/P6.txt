6A. The unexpected results are that we spin up jobs in order: 0, 1, 2, 3, etc… and we expect the output to follow this numbering. Specifically, we would expect to see “hi job #” starting w/ 0 and moving incrementally up followed by “bye job #” starting w/ 0 and moving incremental up. However, we see sometimes certain jobs start/end before we expect them to, and the sequence gets out of order. For example, 

	Hi Job 5
	Hi Job 4
	Hi Job 6
	Hi Job 7
	Bye Job 5Bye Job 4Bye Job 6Bye Job 

We see job 5 got ahead of job 4. This affects how we program in parallel because if certain jobs finish/start out of sequence, this may pose problems for our code. For example, let’s say we are programming in parallel and one processes is updating a parameter while a second processes which is to occur after the first, takes that parameter and puts it into a function. If the sequence here gets mixed up, then the second process may pull a non-updated parameter and will plug that into the function resulting in an incorrect output. 

6B. For very small sleep times (e.g., 10^-6, 10^-5), we see the ratio between serial time and parallel time to be less than 1, meaning that it actually takes longer for parallel processes to complete the loops than the serial process. However, serial's advantage begins to give way (exponentially) to the parallel processes being faster as wait time increases (e.g., 10^-4, 10^-3). The growth in advantage begins to slow however and the ratio approaches a value of 16 as time gets larger and more substantial and closer to wait time of 1 second (e.g., 10^-1, 10^0). I initially expected to see the graph approach a value of 4, as that is the number of processes we have created and 16 is just an arbitrary number of loops.  

