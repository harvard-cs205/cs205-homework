For this question i collaborated with Virgile Audi.

########
#Part 1#
########

After adding code to compute, for each foreground pixel, the minimum of its 4 neighboring pixels and itself, I saw the following results.

Maze 1:
Finished after 883 iterations, 214.56256 ms total, 0.242992706682 ms per iteration
Found 2 regions

Maze 2:
Finished after 522 iterations, 126.54344 ms total, 0.242420383142 ms per iteration
Found 35 regions

########
#Part 2#
########

After adding the optimization to replace each label with the label of its label (i.e. ‘grandparent’), I saw the following results:

Maze 1:
Finished after 529 iterations, 128.33672 ms total, 0.242602495274 ms per iteration
Found 2 regions

Maze 2:
Finished after 273 iterations, 63.26896 ms total, 0.231754432234 ms per iteration
Found 35 regions

########
#Part 3#
########

After adding the optimization for child regions to merge their old and new parent whenever they change to a new label, I saw the following results:

Maze 1:
Finished after 10 iterations, 2.38936 ms total, 0.238936 ms per iteration
Found 2 regions

Maze 2:
Finished after 10 iterations, 2.31816 ms total, 0.231816 ms per iteration
Found 35 regions

########
#Part 4#
########

After adding the optimization where a single thread fetches grandparents and remembers the last fetch it performed, I saw the following results:

Maze 1:
Finished after 10 iterations, 11.134 ms total, 1.1134 ms per iteration
Found 2 regions

Maze 2:
Finished after 9 iterations, 9.9276 ms total, 1.10306666667 ms per iteration
Found 35 regions


We see that in this case, our speed is slower than that of Part 3 for both mazes. This means that the serialization of only having one thread do the work takes longer than having multiple threads going to memory to check each label’s grandparent. I don’t think this necessarily means this is an unreasonable choice, but instead it just was not an optimization for this particular problem. 

I can imagine a scenario however, where we either a) have nearly all pixels having the same label/grandparent in a local group so that this process very rarely requires any global memory reads at all for the single thread which remembers its last fetch and that if we had not serialized the process for one thread that the time required would be longer for many threads or b) a GPU that has an incredibly slow GPU to memory speed that in fact the serialization is an optimization and will reduce overall time. 


########
#Part 5#
########

Explain what would happen if instead of using the atomic_min() operation, one would use the min() function. Your explanation should consider whether the final result would still be correct, what might be the impact on the performance of the algorithm (time and iterations), could a value in labels ever increase, and could it increase between iterations?

If we use min(), it would likely not be guaranteed that we would get the same answer that we would get with atomic_min(). Atomic min ensures we do not have overwrites, so min() by itself could pose problems. Atomic mean accesses are serialized, however, so I imagine there is an impact on performance here but it at least guarantees the right answer vs. that of min().